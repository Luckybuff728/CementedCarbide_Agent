"""
å†…å®¹æå–å™¨ - ä» Agent ç”Ÿæˆçš„ Markdown ä¸­æå–ç»“æ„åŒ–æ•°æ®

ç”¨äºï¼š
1. ä» Optimizer è¾“å‡ºä¸­æå– P1/P2/P3 æ–¹æ¡ˆæ‘˜è¦
2. ä» Experimenter è¾“å‡ºä¸­æå–å·¥å•ä¿¡æ¯
"""
import re
import json
from typing import Dict, Any, Optional, List
from datetime import datetime
from loguru import logger


class ContentExtractor:
    """
    å†…å®¹æå–å™¨
    
    ä» Agent ç”Ÿæˆçš„ Markdown æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®ï¼Œ
    ç”¨äºå‰ç«¯æ˜¾ç¤ºå¡ç‰‡å’Œæä¾›ä¸‹è½½åŠŸèƒ½ã€‚
    """
    
    @staticmethod
    def extract_optimization_plans(content: str) -> Optional[Dict[str, Any]]:
        """
        ä» Optimizer è¾“å‡ºä¸­æå–ä¼˜åŒ–æ–¹æ¡ˆæ‘˜è¦
        
        æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        1. å¤šæ–¹æ¡ˆæ ¼å¼ï¼š## P1 æˆåˆ†ä¼˜åŒ–æ–¹æ¡ˆ / ## P2 ç»“æ„ä¼˜åŒ–æ–¹æ¡ˆ / ## P3 å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆ
        2. å•æ–¹æ¡ˆæ ¼å¼ï¼š# æˆåˆ†ä¼˜åŒ–æ–¹æ¡ˆ / # ç»“æ„ä¼˜åŒ–æ–¹æ¡ˆ / # å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆ
        
        Args:
            content: Optimizer Agent ç”Ÿæˆçš„ Markdown æ–‡æœ¬
            
        Returns:
            ç»“æ„åŒ–çš„ä¼˜åŒ–æ–¹æ¡ˆæ•°æ®
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¼˜åŒ–æ–¹æ¡ˆç›¸å…³å†…å®¹
        has_optimization = any(kw in content for kw in ['ä¼˜åŒ–æ–¹æ¡ˆ', 'æˆåˆ†ä¼˜åŒ–', 'ç»“æ„ä¼˜åŒ–', 'å·¥è‰ºä¼˜åŒ–', 'P1', 'P2', 'P3'])
        if not content or not has_optimization:
            return None
            
        try:
            plans = {
                "type": "optimization_plans",
                "timestamp": datetime.now().isoformat(),
                "plans": []
            }
            
            # === å¤šæ–¹æ¡ˆæ ¼å¼æå–ï¼ˆ## P1/P2/P3ï¼‰ ===
            
            # æå– P1 æˆåˆ†ä¼˜åŒ–
            p1_match = re.search(
                r'##\s*P1[^#]*?æˆåˆ†ä¼˜åŒ–[^#]*?\n(.*?)(?=##\s*P2|##\s*P3|---|\Z)', 
                content, 
                re.DOTALL | re.IGNORECASE
            )
            if p1_match:
                p1_content = p1_match.group(1)
                plan_name = ContentExtractor._extract_plan_name(p1_content)
                plans["plans"].append({
                    "id": "P1",
                    "name": plan_name or "æˆåˆ†ä¼˜åŒ–æ–¹æ¡ˆ",
                    "category": "æˆåˆ†ä¼˜åŒ–",
                    "icon": "ğŸ¯",
                    "summary": ContentExtractor._extract_summary(p1_content, "æˆåˆ†"),
                    "key_changes": ContentExtractor._extract_table_changes(p1_content),
                    "expected_effect": ContentExtractor._extract_expected_effect(p1_content)
                })
            
            # æå– P2 ç»“æ„ä¼˜åŒ–
            p2_match = re.search(
                r'##\s*P2[^#]*?ç»“æ„ä¼˜åŒ–[^#]*?\n(.*?)(?=##\s*P1|##\s*P3|---|\Z)', 
                content, 
                re.DOTALL | re.IGNORECASE
            )
            if p2_match:
                p2_content = p2_match.group(1)
                plan_name = ContentExtractor._extract_plan_name(p2_content)
                plans["plans"].append({
                    "id": "P2",
                    "name": plan_name or "ç»“æ„ä¼˜åŒ–æ–¹æ¡ˆ",
                    "category": "ç»“æ„ä¼˜åŒ–",
                    "icon": "ğŸ—ï¸",
                    "summary": ContentExtractor._extract_summary(p2_content, "ç»“æ„"),
                    "key_changes": ContentExtractor._extract_list_items(p2_content),
                    "expected_effect": ContentExtractor._extract_expected_effect(p2_content)
                })
            
            # æå– P3 å·¥è‰ºä¼˜åŒ–
            p3_match = re.search(
                r'##\s*P3[^#]*?å·¥è‰ºä¼˜åŒ–[^#]*?\n(.*?)(?=##\s*P1|##\s*P2|##\s*ç»¼åˆ|---|\Z)', 
                content, 
                re.DOTALL | re.IGNORECASE
            )
            if p3_match:
                p3_content = p3_match.group(1)
                plan_name = ContentExtractor._extract_plan_name(p3_content)
                plans["plans"].append({
                    "id": "P3",
                    "name": plan_name or "å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆ",
                    "category": "å·¥è‰ºä¼˜åŒ–",
                    "icon": "âš¡",
                    "summary": ContentExtractor._extract_summary(p3_content, "å·¥è‰º"),
                    "key_changes": ContentExtractor._extract_table_changes(p3_content),
                    "expected_effect": ContentExtractor._extract_expected_effect(p3_content)
                })
            
            # === å•æ–¹æ¡ˆæ ¼å¼æå–ï¼ˆ# æˆåˆ†/ç»“æ„/å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆï¼‰ ===
            if not plans["plans"]:
                # å•ç‹¬çš„æˆåˆ†ä¼˜åŒ–æ–¹æ¡ˆ
                single_p1 = re.search(
                    r'#\s*æˆåˆ†ä¼˜åŒ–æ–¹æ¡ˆ\s*\n(.*?)(?=#\s*[^#]|\Z)', 
                    content, 
                    re.DOTALL | re.IGNORECASE
                )
                if single_p1:
                    p1_content = single_p1.group(1)
                    plan_name = ContentExtractor._extract_plan_name(p1_content)
                    plans["plans"].append({
                        "id": "P1",
                        "name": plan_name or "æˆåˆ†ä¼˜åŒ–æ–¹æ¡ˆ",
                        "category": "æˆåˆ†ä¼˜åŒ–",
                        "icon": "ğŸ¯",
                        "summary": ContentExtractor._extract_summary(p1_content, "æˆåˆ†"),
                        "key_changes": ContentExtractor._extract_table_changes(p1_content),
                        "expected_effect": ContentExtractor._extract_expected_effect(p1_content)
                    })
                
                # å•ç‹¬çš„ç»“æ„ä¼˜åŒ–æ–¹æ¡ˆ
                single_p2 = re.search(
                    r'#\s*ç»“æ„ä¼˜åŒ–æ–¹æ¡ˆ\s*\n(.*?)(?=#\s*[^#]|\Z)', 
                    content, 
                    re.DOTALL | re.IGNORECASE
                )
                if single_p2:
                    p2_content = single_p2.group(1)
                    plan_name = ContentExtractor._extract_plan_name(p2_content)
                    plans["plans"].append({
                        "id": "P2",
                        "name": plan_name or "ç»“æ„ä¼˜åŒ–æ–¹æ¡ˆ",
                        "category": "ç»“æ„ä¼˜åŒ–",
                        "icon": "ğŸ—ï¸",
                        "summary": ContentExtractor._extract_summary(p2_content, "ç»“æ„"),
                        "key_changes": ContentExtractor._extract_list_items(p2_content),
                        "expected_effect": ContentExtractor._extract_expected_effect(p2_content)
                    })
                
                # å•ç‹¬çš„å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆ
                single_p3 = re.search(
                    r'#\s*å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆ\s*\n(.*?)(?=#\s*[^#]|\Z)', 
                    content, 
                    re.DOTALL | re.IGNORECASE
                )
                if single_p3:
                    p3_content = single_p3.group(1)
                    plan_name = ContentExtractor._extract_plan_name(p3_content)
                    plans["plans"].append({
                        "id": "P3",
                        "name": plan_name or "å·¥è‰ºä¼˜åŒ–æ–¹æ¡ˆ",
                        "category": "å·¥è‰ºä¼˜åŒ–",
                        "icon": "âš¡",
                        "summary": ContentExtractor._extract_summary(p3_content, "å·¥è‰º"),
                        "key_changes": ContentExtractor._extract_table_changes(p3_content),
                        "expected_effect": ContentExtractor._extract_expected_effect(p3_content)
                    })
            
            # æå–æ¨èæ–¹æ¡ˆ
            recommend_match = re.search(
                r'\*\*æ¨èæ–¹æ¡ˆ[ï¼š:]\s*(P\d)\*\*',
                content,
                re.IGNORECASE
            )
            if recommend_match:
                plans["recommended"] = recommend_match.group(1)
            
            # åªæœ‰æå–åˆ°æ–¹æ¡ˆæ‰è¿”å›
            if plans["plans"]:
                logger.info(f"[ContentExtractor] æå–åˆ° {len(plans['plans'])} ä¸ªä¼˜åŒ–æ–¹æ¡ˆ")
                return plans
                
            return None
            
        except Exception as e:
            logger.error(f"[ContentExtractor] æå–ä¼˜åŒ–æ–¹æ¡ˆå¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_plan_name(content: str) -> Optional[str]:
        """æå–æ–¹æ¡ˆåç§°"""
        # åŒ¹é… **æ–¹æ¡ˆåç§°ï¼š** xxx æˆ– **æ–¹æ¡ˆåç§°:** xxx
        name_match = re.search(
            r'\*\*æ–¹æ¡ˆåç§°[ï¼š:]\*\*\s*([^\n]+)',
            content
        )
        if name_match:
            name = name_match.group(1).strip()
            # æ¸…ç†å¯èƒ½çš„å¼•å·å’Œæ–¹æ‹¬å·
            name = re.sub(r'^[\[\]"\']+|[\[\]"\']+$', '', name)
            return name[:50] if name else None  # é™åˆ¶é•¿åº¦
        return None
    
    @staticmethod
    def extract_workorder(content: str) -> Optional[Dict[str, Any]]:
        """
        ä» Experimenter è¾“å‡ºä¸­æå–å®éªŒå·¥å•ä¿¡æ¯
        
        Args:
            content: Experimenter Agent ç”Ÿæˆçš„ Markdown æ–‡æœ¬
            
        Returns:
            ç»“æ„åŒ–çš„å·¥å•æ•°æ®
        """
        # åªæœ‰æ˜ç¡®åŒ…å« "# å®éªŒå·¥å•" æ ‡é¢˜æ—¶æ‰æå–ï¼Œé¿å…è¯¯åˆ¤
        if not content or not re.search(r'^#\s*å®éªŒå·¥å•', content, re.MULTILINE):
            return None
            
        try:
            # ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆå·¥å•ç¼–å·å’Œæ—¶é—´æˆ³
            now = datetime.now()
            workorder = {
                "type": "workorder",
                "workorder_id": f"WO-{now.strftime('%Y%m%d')}-{now.strftime('%H%M%S')}",
                "timestamp": now.isoformat(),
                "generated_time": now.strftime('%Y-%m-%d %H:%M:%S'),
            }
            
            # æå–ä¼˜åŒ–æ–¹æ¡ˆç±»å‹
            opt_match = re.search(r'ä¼˜åŒ–æ–¹æ¡ˆ[ï¼š:]\s*(P\d)', content)
            if opt_match:
                workorder["optimization_type"] = opt_match.group(1)
            
            # æå–æ–¹æ¡ˆåç§°
            plan_name_match = re.search(
                r'æ–¹æ¡ˆåç§°[ï¼š:]\s*([^\n]+)',
                content
            )
            if plan_name_match:
                plan_name = plan_name_match.group(1).strip()
                # æ¸…ç†å¯èƒ½çš„å¼•å·å’Œæ–¹æ‹¬å·
                plan_name = re.sub(r'^[\[\]"\']+|[\[\]"\']+$', '', plan_name)
                workorder["plan_name"] = plan_name[:60]
            
            # æå–å®éªŒç›®çš„
            purpose_match = re.search(
                r'##\s*å®éªŒç›®çš„\s*\n(.*?)(?=##|\Z)',
                content,
                re.DOTALL
            )
            if purpose_match:
                workorder["purpose"] = purpose_match.group(1).strip()[:200]
            
            # æå–æˆåˆ†é…æ¯”è¡¨æ ¼
            composition = ContentExtractor._extract_composition_table(content)
            if composition:
                workorder["composition"] = composition
            
            # æå–å·¥è‰ºå‚æ•°è¡¨æ ¼
            process_params = ContentExtractor._extract_process_table(content)
            if process_params:
                workorder["process_params"] = process_params
            
            # æå–é¢„æœŸç»“æœ
            expected = ContentExtractor._extract_expected_results(content)
            if expected:
                workorder["expected_results"] = expected
            
            # å­˜å‚¨å®Œæ•´ Markdown ç”¨äºä¸‹è½½
            workorder["full_content"] = content
            
            logger.info(f"[ContentExtractor] æå–å·¥å•: {workorder.get('workorder_id')}")
            return workorder
            
        except Exception as e:
            logger.error(f"[ContentExtractor] æå–å·¥å•å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_summary(content: str, focus: str) -> str:
        """æå–æ–¹æ¡ˆæ‘˜è¦"""
        # å°è¯•ä»"å½“å‰é—®é¢˜"éƒ¨åˆ†æå–
        problem_match = re.search(
            r'###\s*å½“å‰é—®é¢˜\s*\n(.*?)(?=###|\Z)',
            content,
            re.DOTALL
        )
        if problem_match:
            text = problem_match.group(1).strip()
            # å–ç¬¬ä¸€å¥æˆ–å‰100å­—ç¬¦
            first_line = text.split('\n')[0].strip()
            if first_line:
                return first_line[:100]
        
        return f"é’ˆå¯¹{focus}è¿›è¡Œä¼˜åŒ–è°ƒæ•´"
    
    @staticmethod
    def _extract_table_changes(content: str) -> List[Dict[str, str]]:
        """ä»è¡¨æ ¼ä¸­æå–å‚æ•°å˜åŒ–"""
        changes = []
        
        # åŒ¹é…è¡¨æ ¼è¡Œï¼š| å‚æ•° | å½“å‰å€¼ | å»ºè®®å€¼ | ... |
        table_pattern = r'\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|'
        matches = re.findall(table_pattern, content)
        
        for match in matches:
            param, current, suggested = match
            param = param.strip()
            current = current.strip()
            suggested = suggested.strip()
            
            # è·³è¿‡è¡¨å¤´
            if param in ['å‚æ•°', '---', 'å…ƒç´ '] or '---' in param:
                continue
            if current in ['å½“å‰å€¼', '---'] or '---' in current:
                continue
                
            changes.append({
                "param": param,
                "from": current,
                "to": suggested
            })
        
        return changes[:5]  # æœ€å¤šè¿”å›5é¡¹
    
    @staticmethod
    def _extract_list_items(content: str) -> List[Dict[str, str]]:
        """ä»åˆ—è¡¨ä¸­æå–å˜åŒ–é¡¹"""
        changes = []
        
        # åŒ¹é…åˆ—è¡¨é¡¹ï¼š- xxx: yyy æˆ– - xxx â†’ yyy
        list_pattern = r'-\s*([^:ï¼šâ†’\n]+)[ï¼š:â†’]\s*([^\n]+)'
        matches = re.findall(list_pattern, content)
        
        for match in matches:
            param, value = match
            changes.append({
                "param": param.strip(),
                "to": value.strip()
            })
        
        return changes[:5]
    
    @staticmethod
    def _extract_expected_effect(content: str) -> str:
        """æå–é¢„æœŸæ•ˆæœ"""
        effect_match = re.search(
            r'###\s*é¢„æœŸæ•ˆæœ\s*\n(.*?)(?=###|---|##|\Z)',
            content,
            re.DOTALL
        )
        if effect_match:
            text = effect_match.group(1).strip()
            # åˆå¹¶å¤šè¡Œä¸ºä¸€è¡Œ
            lines = [l.strip().lstrip('-').strip() for l in text.split('\n') if l.strip()]
            return 'ï¼›'.join(lines[:3])
        
        return ""
    
    @staticmethod
    def _extract_composition_table(content: str) -> Dict[str, float]:
        """æå–æˆåˆ†é…æ¯”"""
        composition = {}
        
        # æŸ¥æ‰¾æˆåˆ†é…æ¯”éƒ¨åˆ†
        comp_match = re.search(
            r'###\s*æˆåˆ†é…æ¯”\s*\n(.*?)(?=###|\Z)',
            content,
            re.DOTALL
        )
        if not comp_match:
            return composition
            
        table_content = comp_match.group(1)
        
        # åŒ¹é…å…ƒç´ å’Œå«é‡
        patterns = [
            (r'\|\s*Al\s*\|\s*([\d.]+)', 'Al'),
            (r'\|\s*Ti\s*\|\s*([\d.]+)', 'Ti'),
            (r'\|\s*N\s*\|\s*([\d.]+)', 'N'),
        ]
        
        for pattern, element in patterns:
            match = re.search(pattern, table_content, re.IGNORECASE)
            if match:
                try:
                    composition[element] = float(match.group(1))
                except ValueError:
                    pass
        
        return composition
    
    @staticmethod
    def _extract_process_table(content: str) -> Dict[str, Any]:
        """æå–å·¥è‰ºå‚æ•°"""
        params = {}
        
        # æŸ¥æ‰¾å·¥è‰ºå‚æ•°éƒ¨åˆ†
        proc_match = re.search(
            r'###\s*å·¥è‰ºå‚æ•°\s*\n(.*?)(?=###|\Z)',
            content,
            re.DOTALL
        )
        if not proc_match:
            return params
            
        table_content = proc_match.group(1)
        
        # åŒ¹é…å„å‚æ•°
        patterns = [
            (r'æ²‰ç§¯æ¸©åº¦\s*\|\s*([\d.]+)', 'temperature'),
            (r'åå‹\s*\|\s*-?([\d.]+)', 'bias_voltage'),
            (r'Nâ‚‚æµé‡\s*\|\s*([\d.]+)', 'n2_flow'),
            (r'Aræµé‡\s*\|\s*([\d.]+)', 'ar_flow'),
            (r'æ²‰ç§¯æ—¶é—´\s*\|\s*([\d.]+)', 'deposition_time'),
        ]
        
        for pattern, key in patterns:
            match = re.search(pattern, table_content)
            if match:
                try:
                    params[key] = float(match.group(1))
                except ValueError:
                    pass
        
        return params
    
    @staticmethod
    def _extract_expected_results(content: str) -> Dict[str, Any]:
        """æå–é¢„æœŸç»“æœ"""
        results = {}
        
        # æŸ¥æ‰¾é¢„æœŸç»“æœéƒ¨åˆ†
        exp_match = re.search(
            r'##\s*é¢„æœŸç»“æœ\s*\n(.*?)(?=##|\Z)',
            content,
            re.DOTALL
        )
        if not exp_match:
            return results
            
        table_content = exp_match.group(1)
        
        # åŒ¹é…å„æŒ‡æ ‡
        patterns = [
            (r'ç¡¬åº¦\s*\|\s*([\d.]+)', 'hardness'),
            (r'ç»“åˆåŠ›\s*\|\s*([\d.]+)', 'adhesion'),
            (r'å¼¹æ€§æ¨¡é‡\s*\|\s*([\d.]+)', 'elastic_modulus'),
        ]
        
        for pattern, key in patterns:
            match = re.search(pattern, table_content)
            if match:
                try:
                    results[key] = float(match.group(1))
                except ValueError:
                    pass
        
        return results


def extract_structured_content(content: str, agent_name: str) -> Optional[Dict[str, Any]]:
    """
    æ ¹æ® Agent ç±»å‹æå–ç»“æ„åŒ–å†…å®¹
    
    Args:
        content: Agent ç”Ÿæˆçš„å®Œæ•´ Markdown æ–‡æœ¬
        agent_name: Agent åç§°ï¼ˆOptimizer/Experimenterï¼‰
        
    Returns:
        æå–çš„ç»“æ„åŒ–æ•°æ®ï¼Œå¦‚æœæ— æ³•æå–è¿”å› None
    """
    if not content or len(content) < 100:
        return None
    
    if agent_name == "Optimizer":
        return ContentExtractor.extract_optimization_plans(content)
    elif agent_name == "Experimenter":
        return ContentExtractor.extract_workorder(content)
    
    return None
